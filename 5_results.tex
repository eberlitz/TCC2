\section{Results}\label{chap:results}




For the evaluation, we propose to do qualitative measure based on a manual inspection of the most similar words to a hand picked set of words and see if they are in fact similar or not to the other words regarding similarity, relatedness and also the syntactic similarity.
Also a quantitative analyses is proposed by using the WordSim353 dataset from \citetexto{Finkelstein:2001:PSC:371920.372094}, which is a dataset regarding word similarity versus relatedness. As all the pairs in this dataset are in English, they will be manually translated to Portuguese to be able to compare the results with all the techniques.
To better visualize the performance of each technique the precision-recall curve draws will be used to describes the embeddings affinity.
Another quantitative analysis will be done to see if the recall increase using the ENSEPRO dataset. If it increases it will improve the quality of the ENSEPRO system. 




\subsection{Quantitative Evaluation}\label{chap:results:quantitative}




% wang2vec, s50-m2-sg0, 0.5675826685662275, 8.205893134030749e-07, 0.5635628524347914, 1.0195643908100097e-06, 0.0
% wang2vec, s100-m2-sg0, 0.6131396734513458, 5.651106360321298e-08, 0.5921967327702674, 2.0349725697447497e-07, 0.0
% wang2vec, s300-m2-sg0, 0.6888797495139529, 2.2484749974574857e-10, 0.6432787009717997, 7.523225919215496e-09, 0.0
% wang2vec, s600-m2-sg0, 0.6853053668701915, 3.029007857846718e-10, 0.6696174992956536, 1.0673762628380258e-09, 0.0
% wang2vec, s1000-m2-sg0, 0.6766001068757364, 6.151160064691805e-10, 0.6735519256012915, 7.838630653736625e-10, 0.0
% wang2vec, s50-m2-sg1, 0.645149430139591, 6.589637891664643e-09, 0.6351256953495611, 1.3263902162497147e-08, 0.0
% wang2vec, s100-m2-sg1, 0.7413591760234222, 1.6335829856029777e-12, 0.6885607956010713, 2.3094619628306546e-10, 0.0
% wang2vec, s300-m2-sg1, 0.745012387876388, 1.1096392933572878e-12, 0.6870164067361413, 2.62772837988064e-10, 0.0
% wang2vec, s600-m2-sg1, 0.7210383344592625, 1.2550799293267612e-11, 0.7171069323242951, 1.824221491301501e-11, 0.0
% wang2vec, s1000-m2-sg1, 0.6930506286220262, 1.5795313521680925e-10, 0.7388634022748809, 2.119741903465055e-12, 0.0
% word2vec, s50-w5-m2-sg0.bin, 0.581229529126566, 3.84174388531859e-07, 0.5851520874559164, 3.0689482111089004e-07, 0.0
% word2vec, s100-w5-m2-sg0.bin, 0.6298983570863325, 1.8914944333339274e-08, 0.6253483703303488, 2.5624014854855167e-08, 0.0
% word2vec, s300-w5-m2-sg0.bin, 0.6822389764635896, 3.8982651681588046e-10, 0.6601093023903619, 2.2087825850474964e-09, 0.0
% word2vec, s600-w5-m2-sg0.bin, 0.6855398167573925, 2.9707638417289337e-10, 0.6631912696631116, 1.7499347892691779e-09, 0.0
% word2vec, s1000-w5-m2-sg0.bin, 0.6847454215614132, 3.1725458043279284e-10, 0.6623971465522971, 1.8586283009033272e-09, 0.0
% word2vec, s50-w5-m2-sg1.bin, 0.6506441236317141, 4.441702023816473e-09, 0.6316284275223274, 1.6831037829706216e-08, 0.0
% word2vec, s100-w5-m2-sg1.bin, 0.7469612603916977, 9.003604443872392e-13, 0.7080359930133167, 4.222830325088272e-11, 0.0
% word2vec, s300-w5-m2-sg1.bin, 0.7609954038361787, 1.8863142825679156e-13, 0.702637144796903, 6.85621738847557e-11, 0.0
% word2vec, s600-w5-m2-sg1.bin, 0.7386199892517825, 2.173948064170437e-12, 0.7357515377032462, 2.9212784100274446e-12, 0.0
% word2vec, s1000-w5-m2-sg1.bin, 0.6929945042335994, 1.5871171197284068e-10, 0.6918394483640755, 1.7511639382309394e-10, 0.0
% fastText, s50-m2-sg0.vec, 0.6654838350095832, 1.4690168762210383e-09, 0.6658360784574572, 1.4298543411901056e-09, 0.0
% fastText, s100-m2-sg0.vec, 0.7173075319568939, 1.7900157895594544e-11, 0.6960874451630287, 1.2168519646113534e-10, 0.0
% fastText, s300-m2-sg0.vec, 0.7475432934016183, 8.455700537736788e-13, 0.719562855453335, 1.4452565532162868e-11, 0.0
% fastText, s600-m2-sg0.vec, 0.7298204921535301, 5.3177888108039625e-12, 0.7179890849310797, 1.678315747953346e-11, 0.0
% fastText, s1000-m2-sg0.vec, 0.7108943560290044, 3.252646104105637e-11, 0.7115628552985378, 3.0586270484872453e-11, 0.0
% fastText, s50-m2-sg1.vec, 0.7416054449362045, 1.5918680250004441e-12, 0.7120437296247825, 2.9259465642871006e-11, 0.0
% fastText, s100-m2-sg1.vec, 0.7679139432721014, 8.388218575396365e-14, 0.7157954712190935, 2.063712394991865e-11, 0.0
% fastText, s300-m2-sg1.vec, 0.7916024795244279, 4.172248335671122e-15, 0.7834012911922416, 1.2301453367822823e-14, 0.0
% fastText, s600-m2-sg1.vec, 0.7658587738270587, 1.0702167361155195e-13, 0.8137397580925745, 1.7402483297508791e-16, 0.0
% fastText, s1000-m2-sg1.vec, 0.7197230224601823, 1.423352120292654e-11, 0.8060021375718844, 5.532294075730079e-16, 0.0
% word2vecf, n15-s50, 0.47043675193651774, 7.673603880188538e-05, 0.42880406603078586, 0.00036542081239773175, 0.0
% word2vecf, n15-s100, 0.4420071264561769, 0.00022760919709419663, 0.40069946130530176, 0.0009408999372156398, 0.0
% word2vecf, n15-s300, 0.4339133409759349, 0.00030494411522489926, 0.39361749395515355, 0.0011790717533701595, 0.0
% word2vecf, n15-s600, 0.4458088040797816, 0.00019788851587704653, 0.3783565288506934, 0.0018859593744119357, 0.0
% word2vecf, n15-s1000, 0.44290775661265125, 0.00022022046602220827, 0.37925683793957515, 0.0018355446216130676, 0.0
% GloVe, 50.txt, 0.6329096982357285, 1.5429960795806175e-08, 0.6426377992339247, 7.870960989317901e-09, 0.0
% GloVe, 100.txt, 0.6939245763779542, 1.4657747313783288e-10, 0.6977486473809646, 1.053594741063381e-10, 0.0
% GloVe, 300.txt, 0.6920006623855645, 1.7273345787536298e-10, 0.7133552050599951, 2.5914321071641535e-11, 0.0
% GloVe, 600.txt, 0.6677168932041986, 1.236988802854876e-09, 0.7051147677420757, 5.496365284083455e-11, 0.0
% GloVe, 1000.txt, 0.6548580080251044, 3.2643527148291645e-09, 0.7108119190193269, 3.277369731826533e-11, 0.0


% OWM, wup, 0.6224196059044503, 3.9086124786740125e-07, 0.5993354805660435, 1.3336702025718145e-06, 15.384615384615385
% OWM, path, 0.7629920696961829, 1.2781571648596962e-11, 0.638215045981246, 1.5911706121638655e-07, 15.384615384615385
% OWM, wup, 0.5130904887818083, 1.2406652833034867e-05, 0.5101121482658979, 1.4203800232966779e-05, 13.333333333333334
% OWM, path, 0.6755297783884997, 6.699886211511832e-10, 0.537623366025965, 3.8731549459381025e-06, 13.333333333333334


\begin{table}[]
\caption{Word embeddings evaluation on PT65}
\label{tab:estacoes}
\centering%
\begin{minipage}{.5\textwidth}
\begin{tabular}{@{}lllll@{}}
\cmidrule(r){1-4}
\textbf{Embedding Models} &      & \textbf{Size} & \textbf{Pearson} \\ \cmidrule(r){1-4}
GloVe            &               & 50   & 0.63             \\
                 &               & 100  & 0.69             \\
                 &               & 300  & 0.69             \\
                 &               & 600  & 0.67             \\
                 &               & 1000 & 0.65             \\ \cmidrule(r){1-4}
FastText         & CBOW          & 50   & 0.67             \\
                 &               & 100  & 0.72             \\
                 &               & 300  & \textbf{0.75}    \\
                 &               & 600  & 0.73             \\
                 &               & 1000 & 0.71             \\ \cmidrule(lr){2-4}
                 & Skip-Gram     & 50   & 0.74             \\
                 &               & 100  & \textbf{0.77}    \\
                 &               & 300  & \textbf{0.79}    \\
                 &               & 600  & \textbf{0.77}    \\
                 &               & 1000 & 0.72             \\ \cmidrule(r){1-4}
Wang2vec         & CBOW          & 50   & 0.57             \\
                 &               & 100  & 0.61             \\
                 &               & 300  & 0.69             \\
                 &               & 600  & 0.69             \\
                 &               & 1000 & 0.68             \\ \cmidrule(lr){2-4}
                 & Skip-Gram     & 50   & 0.65             \\
                 &               & 100  & \textbf{0.74}    \\
                 &               & 300  & \textbf{0.75}    \\
                 &               & 600  & 0.72             \\
                 &               & 1000 & 0.69             \\ \cmidrule(r){1-4}
Word2vec         & CBOW          & 50   & 0.58             \\
                 &               & 100  & 0.63             \\
                 &               & 300  & 0.68             \\
                 &               & 600  & 0.69             \\
                 &               & 1000 & 0.68             \\ \cmidrule(lr){2-4}
                 & Skip-Gram     & 50   & 0.65             \\
                 &               & 100  & \textbf{0.75}    \\
                 &               & 300  & \textbf{0.76}    \\
                 &               & 600  & 0.74             \\
                 &               & 1000 & 0.69             \\ \cmidrule(r){1-4}
Word2vecf        &               & 50   & 0.47             \\
                 &               & 100  & 0.44             \\
                 &               & 300  & 0.43             \\
                 &               & 600  & 0.45             \\
                 &               & 1000 & 0.44             \\ \cmidrule(r){1-4}
\end{tabular}
\fonte{Made by the author.}
\end{minipage}
\end{table}



\begin{table}[]
\caption{WordNet}
\label{tab:worneteval}
\centering%
\begin{minipage}{.6\textwidth}
\begin{tabular}{@{}lllll@{}}
\cmidrule(r){1-5}
\textbf{Embedding Models} & \textbf{Pearson}          & \textbf{Out of vocabulary ratio} \\ 
\cmidrule(r){1-3}
Path Distance & \textbf{0.76}    & 15.38                   \\
Wu-Palmer     & 0.62             & 15.38                   \\ \cmidrule(r){1-3}
\end{tabular}
\fonte{Made by the author.}
\end{minipage}
\end{table}

\subsection{Qualitative Evaluation}\label{chap:results:quantitative}
