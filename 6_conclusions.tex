\section{Final considerations}\label{chap:conclusions}

The study carried out in this work, indicates that the detection of similarity between words is a very important topic for the NLP segments as summarization, information retrieval, and question answering. Techniques for identifying word similarity can help in a number of NLP tasks such as dialogue systems, question answering, and information retrieval systems. \cite{Islam2007ApplicationsOC,Pilehvar2013,Agirre2009}.

It was also found indications that the expansion of terms using WordNet has several problems, where a word may not be present. Since these lexical bases are of manual construction, they are time-consuming and expensive, and for this reason, not all links will be present and their quality varies from language to language.  There is also no WordNet for all languages \cite{Leeuwenberga2016}. Distributional approaches regarding word similarity have been proven to be more competitive than the thesaurus-based approach, and have been successfully being used to cover out-of-vocabulary items in WordNet.  \cite{gonccalo2018distributional, Agirre2009}.

Thus, it is highlighted in this paper as a contribution, an exploration of the existing techniques regarding word similarity, were we used a distributional approach called word embeddings, adapting existing works to Brazilian Portuguese. We also experiment with other techniques that are solely based on a lexical database such as WordNet, and we evaluate all the different techniques over a common dataset called PT65. Therefore indicating that word embeddings can cover words out of vocabulary and have slightly better results in comparison with WordNet in this particular task. As a second contribution, we adapted the studies of \citetexto{Levy2014} regarding the addition of syntactic context in the training process of word embeddings to a Brazilian Portuguese corpus, finding similar results, but for the task of word similarity against the dataset PT65, it had the worst results.

As a limitation, this work did not compare differences between similarity and relatedness since the dataset does not specific distinguish between them. \citetexto{querido2017lx}, have recently adapted the SimLex-999 and WordSim-353 datasets to Portuguese so it's possible to do a evaluation comparing the performance between similarity and relatedness. Also this work only used the Brazilian Portuguese corpus from the Wikipedia, but accordingly to \citetexto{Fonseca2016} the bigger the corpus is, the better the embeddings, even with mixed Portuguese variants, so it could also be possible to evaluate with a much bigger corpus by joining the European with the Portuguese Wikipedia dumps.

As a future work, we intend to evaluate the different techniques against the work of \citetexto{denis2018} to see if we can improve the ENSEPRO results. As well as to explore how we could use BERT and ELMo language models for word-level tasks such as word similarity as these works represent the state-of-the-art.